{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOylH0Hx2e6Xse0QtqKyYo1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshuaZheng0/Backtest-Trading-Sim/blob/main/RSI-trading-backtest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training and preprocessing libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "#Performance evaluation libraries\n",
        "\n",
        "dataset_train = pd.read_csv(\"4-23 to 7-16 5 min data NQ.csv\")\n",
        "len(dataset_train)"
      ],
      "metadata": {
        "id": "ZSNpCvYjQMh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e9f9e3-83fa-441b-b794-af925059d673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20472"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the Adj close column since it gives the same values as close\n",
        "# create a new column that represents the percentage in price change\n",
        "dataset_train = dataset_train[['time','open', 'high', 'low','close']]\n",
        "dataset_train['PC%'] = [0] * dataset_train.shape[0]\n",
        "dataset_train['PC%'] = (dataset_train['close'].diff()/dataset_train['open'])*100\n",
        "#create rsi column\n",
        "def rsi(ohlc: dataset_train, period: int = 14, round_rsi: bool = True):\n",
        "    \"Implements the RSI indicator as defined by TradingView on March 15, 2021.\"\n",
        "    delta = ohlc[\"close\"].diff()\n",
        "\n",
        "    up = delta.copy()\n",
        "    up[up < 0] = 0\n",
        "    up = pd.Series.ewm(up, alpha=1/period).mean()\n",
        "\n",
        "    down = delta.copy()\n",
        "    down[down > 0] = 0\n",
        "    down *= -1\n",
        "    down = pd.Series.ewm(down, alpha=1/period).mean()\n",
        "\n",
        "    rsi = np.where(up == 0, 0, np.where(down == 0, 100, 100 - (100 / (1 + up / down))))\n",
        "\n",
        "    return np.round(rsi, 2) if round_rsi else rsi\n",
        "\n",
        "\n",
        "dataset_train['rsi'] = [0] * dataset_train.shape[0]\n",
        "dataset_train['rsi'] = rsi(dataset_train)\n",
        "dataset_train[\"PC%\"]=dataset_train[\"PC%\"].fillna(0)\n",
        "dataset_train[\"rsi\"]=dataset_train[\"rsi\"].fillna(0)\n",
        "# #the feature class represents tesla's change the following day\n",
        "# dataset_train['class'] = [0] * dataset_train.shape[0]\n",
        "# dataset_train['class'] = dataset_train['PC%'].apply(lambda x : x >= 0)\n",
        "#if tesla grew class will be indicated as 1\n",
        "# #if tesla plumeted class will be indicated as 0\n",
        "# dataset_train[\"class\"] = dataset_train[\"class\"].replace(True, 1)\n",
        "# dataset_train[\"class\"] = dataset_train[\"class\"].replace(False, 0)\n",
        "# dataset_train['class'] = dataset_train['class'].shift(-1)\n",
        "# dataset_train[\"class\"]=dataset_train[\"class\"].fillna(0)\n",
        "# #if tesla grows for the nesxt 3 days next\n",
        "# dataset_train['nextThreeDays'] = [0] * dataset_train.shape[0]\n",
        "# dataset_train['nextThreeDays'] = (dataset_train['class']+dataset_train['class'].shift(-1)+dataset_train['class'].shift(-2))//3\n",
        "# dataset_train[\"nextThreeDays\"]=dataset_train[\"nextThreeDays\"].fillna(0)\n",
        "# dataset_train[\"nextThreeDays\"].sum()\n",
        "# #the growth of tesla in the past three days\n",
        "# dataset_train['pastThreeDays'] = [0] * dataset_train.shape[0]\n",
        "# dataset_train['pastThreeDays'] = (dataset_train['class'].shift(1)+dataset_train['class'].shift(2)+dataset_train['class'].shift(3))//3\n",
        "# dataset_train[\"pastThreeDays\"]=dataset_train[\"pastThreeDays\"].fillna(0)\n",
        "# dataset_train[\"pastThreeDays\"].sum()\n",
        "dataset_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "7ad-Q7PXQTMD",
        "outputId": "5c341f6d-641b-44a2-fd3f-cfca0127515e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             time      open      high       low     close       PC%    rsi\n",
              "0      1680472800  13262.00  13275.50  13247.00  13251.00  0.000000   0.00\n",
              "1      1680473100  13250.00  13258.25  13244.25  13246.25 -0.035849   0.00\n",
              "2      1680473400  13245.75  13247.75  13236.25  13242.75 -0.026424   0.00\n",
              "3      1680473700  13242.75  13247.75  13235.00  13242.50 -0.001888   0.00\n",
              "4      1680474000  13243.00  13248.50  13243.00  13246.50  0.030205  36.19\n",
              "...           ...       ...       ...       ...       ...       ...    ...\n",
              "20467  1689559500  15683.25  15685.75  15681.00  15685.25  0.017535  59.21\n",
              "20468  1689559800  15685.00  15686.50  15682.00  15682.75 -0.015939  54.87\n",
              "20469  1689560100  15682.75  15684.25  15681.25  15682.50 -0.001594  54.44\n",
              "20470  1689560400  15682.00  15683.00  15681.25  15682.25 -0.001594  53.98\n",
              "20471  1689560700  15682.75  15683.00  15681.25  15681.75 -0.003188  53.03\n",
              "\n",
              "[20472 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-8ff0aad2-77df-4c4c-aa2a-9321a1363c1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>PC%</th>\n",
              "      <th>rsi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1680472800</td>\n",
              "      <td>13262.00</td>\n",
              "      <td>13275.50</td>\n",
              "      <td>13247.00</td>\n",
              "      <td>13251.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1680473100</td>\n",
              "      <td>13250.00</td>\n",
              "      <td>13258.25</td>\n",
              "      <td>13244.25</td>\n",
              "      <td>13246.25</td>\n",
              "      <td>-0.035849</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1680473400</td>\n",
              "      <td>13245.75</td>\n",
              "      <td>13247.75</td>\n",
              "      <td>13236.25</td>\n",
              "      <td>13242.75</td>\n",
              "      <td>-0.026424</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1680473700</td>\n",
              "      <td>13242.75</td>\n",
              "      <td>13247.75</td>\n",
              "      <td>13235.00</td>\n",
              "      <td>13242.50</td>\n",
              "      <td>-0.001888</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1680474000</td>\n",
              "      <td>13243.00</td>\n",
              "      <td>13248.50</td>\n",
              "      <td>13243.00</td>\n",
              "      <td>13246.50</td>\n",
              "      <td>0.030205</td>\n",
              "      <td>36.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20467</th>\n",
              "      <td>1689559500</td>\n",
              "      <td>15683.25</td>\n",
              "      <td>15685.75</td>\n",
              "      <td>15681.00</td>\n",
              "      <td>15685.25</td>\n",
              "      <td>0.017535</td>\n",
              "      <td>59.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20468</th>\n",
              "      <td>1689559800</td>\n",
              "      <td>15685.00</td>\n",
              "      <td>15686.50</td>\n",
              "      <td>15682.00</td>\n",
              "      <td>15682.75</td>\n",
              "      <td>-0.015939</td>\n",
              "      <td>54.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20469</th>\n",
              "      <td>1689560100</td>\n",
              "      <td>15682.75</td>\n",
              "      <td>15684.25</td>\n",
              "      <td>15681.25</td>\n",
              "      <td>15682.50</td>\n",
              "      <td>-0.001594</td>\n",
              "      <td>54.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20470</th>\n",
              "      <td>1689560400</td>\n",
              "      <td>15682.00</td>\n",
              "      <td>15683.00</td>\n",
              "      <td>15681.25</td>\n",
              "      <td>15682.25</td>\n",
              "      <td>-0.001594</td>\n",
              "      <td>53.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20471</th>\n",
              "      <td>1689560700</td>\n",
              "      <td>15682.75</td>\n",
              "      <td>15683.00</td>\n",
              "      <td>15681.25</td>\n",
              "      <td>15681.75</td>\n",
              "      <td>-0.003188</td>\n",
              "      <td>53.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20472 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ff0aad2-77df-4c4c-aa2a-9321a1363c1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-74bc3c16-df73-444b-aab0-77aaa2f733d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74bc3c16-df73-444b-aab0-77aaa2f733d5')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-74bc3c16-df73-444b-aab0-77aaa2f733d5 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ff0aad2-77df-4c4c-aa2a-9321a1363c1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ff0aad2-77df-4c4c-aa2a-9321a1363c1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the rsi, open, and change colums are shifted down by 15 days\n",
        "#since rsi requires the previous 15 days to calculate\n",
        "#dont worry that the last 15 values in the rsi array are null\n",
        "#they occur because of the initial shift.\n",
        "rsi = dataset_train['rsi'].shift(-15)\n",
        "open = dataset_train['open'].shift(-15)\n",
        "change =  dataset_train['PC%'].shift(-15)\n",
        "time = dataset_train['time'].shift(-15)\n",
        "\n",
        "sum_of_all_percentages = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "5CkgXmsTQjqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(rsi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d0B_PNajaLg",
        "outputId": "45e6a50a-3fda-4234-ad9c-c86c25c41948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20472"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "import collections\n",
        "\n",
        "def consume(iterator, n):\n",
        "    \"Advance the iterator n-steps ahead. If n is none, consume entirely.\"\n",
        "    # Use functions that consume iterators at C speed.\n",
        "    if n is None:\n",
        "        # feed the entire iterator into a zero-length deque\n",
        "        collections.deque(iterator, maxlen=0)\n",
        "    else:\n",
        "        # advance to the empty slice starting at position n\n",
        "        next(islice(iterator, n, n), None)"
      ],
      "metadata": {
        "id": "Np0El3pafw2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6BIDjsRP4hK",
        "outputId": "639b2797-e97b-4e79-944a-c8473016a9f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "52.07014125669751\n",
            "[True, False, False, False, False, False, True, True, True, True, False, False, True, False, False, False, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, False, False, False, False, False, False, False, True, True, False, False, True, False, False, False, True, True, True, True, True, False, False, False, True, False, True, True, False, False, False, False, True, False, False, False, True, True, False, False, True, True, True, True, True, False, False, False, False, False, False, False, False, False, True, True, True, False, False, False, False, True, False, False, True, True, False, False, True, True, False, False, False, True, False, True, False, True, True, False, True, True, True, True, False, True, True, False, False, False, False, True, False, False, True, True, False, True, True, True, True, True, True, False, False, True, True, False, True, False, False, False, True, False, True, True, False, False, True, True, True, False, False, False, False, False, False, False, False, True, True, False, False, True, True, True, True, False, True, False, False, False, False, False, True, True, True, False, False, False, True, False, False, False, False, False, False, True, True, False, True, True, True, True, False, False, False, False, False, True, True, True, False, False, True, False, True, True, True, False, True, True, True, True, True, True, False, False, False, True, True, False, True, True, True, False, False, False, True, True, True, False, True, True, False, True, False, False, False, False, False, False, False, False, False, False, False, True, True, False, True, True, True, True, False, True, True, True, True, True, True, False, True, False, True, True, True, False, False, True, True, True, True, True, False, True, True, True, False, False, False, False, True, False, False, True, False, True, False, False, True, False, True, True, True, True, False, False, False, True, False, True, False, False, True, True, True, True, False, False, False, True, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, True, True, False, False, True, True, False, False, False, False, False, False, False, False, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, False, True, True, True, True, False, False, False, True, False, True, False, True, False, False, True, True, True, True, True, False, True, True, True, True, True, True, False, False, True, True, False, False, False, False, True, True, True, True, False, False, True, True, False, False, True, False, False, True, True, True, False, True, True, False, False, False, False, True, True, True, False, False, True, True, False, False, False, False, False, False, False, False, True, True, True, True, False, True, True, True, False, True, True, False, False, True, True, True, False, True, False, False, False, True, False, True, True, True, True, False, False, False, False, True, True, True, False, False, False, True, True, True, True, True, True, False, True, False, False, False, True, True, True, True, False, True, False, False, True, False, False, True, False, False, False, True, False, True, False, True, False, True, False, False, False, False, False, True, False, False, True, True, True, True, True, True, False, True, False, False, False, False, True, False, False, True, True, False, False, True, True, False, False, False, True, True, False, True, False, False, True, True, False, True, True, True, False, False, False, True, True, False, False, True, True, True, True, False, True, False, True, True, False, True, True, False, True, False, False, False, True, True, True, True, False, True, True, False, False, True, False, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, False, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False, True, True, False, False, False, True, True, False, True, True, True, True, False, True, True, False, False, True, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, False, False, True, False, True, True, False, True, True, True, True, True, False, True, True, True, False, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, False, False, True, True, False, True, True, False, True, True, True, False, True, False, True, False, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, False, False, False, True, True, False, False, True, True, False, False, True, True, False, False, False, False, True, False, False, False, True, False, False, False, True, False, True, True, False, True, True, True, False, False, True, True, False, False, False, False, False, False, False, True, True, True, True, True, False, True, False, True, False, False, True, True, True, False, False, False, False, True, False, False, False, False, False, False, True, False, False, True, True, True, True, True, True, False, True, False, False, True, True, True, True, True, True, False, True, True, False, True, True, False, False, False, True, True, True, True, False, False, False, False, True, True, False, True, True, False, True, False, True, False, True, True, True, True, True, True, False, False, True, True, False, True, False, False, True, True, True, True, False, False, True, False, True, False, False, True, True, True, False, False, False, True, False, False, True, False, True, True, True, True, False, False, False, False, True, True, False, False, False, False, True, False, False, True, False, True, True, True, True, False, True, True, True, True, False, True, False, False, True, False, False, True, True, True, False, True, True, True, True, True, False, False, False, False, False, False, True, True, False, False, False, False, False, True, False, False, True, True, False, False, True, False, True, False, False, True, True, True, True, True, True, False, True, True, False, False, False, False, True, True, False, True, True, True, True, True, False, True, True, True, False, False, False, True, True, True, False, False, False, True, False, True, True, True, True, False, True, True, False, True, True, True, True, False, True, True, True, True, True, False, False, False, False, True, False, True, False, False, True, True, True, True, False, False, True, True, False, True, True, True, True, False, True, True, True, False, True, True, False, True, True, True, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, False, True, True, True, True, False, False, True, True, False, True, False, True, False, False, True, True, True, False, True, True, False, False, True, True, False, True, True, False, True, False, False, False, False, False, True, False, True, True, True, True, True, False, True, True, True, True, False, True, True, False, True, True, False, True, True, False, False, False, True, False, True, True, True, False, False, False, False, True, False, False, True, True, True, False, True, True, True, True, False, True, False, False, True, True, True, True, False, False, True, True, True, True, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, True, False, True, True, False, False, True, True, False, False, False, True, True, False, True, False, False, True, True, True, True, True, True, False, True, True, True, False, False, False, False, True, True, True, False, False, True, False, True, True, False, True, False, True, True, False, False, True, False, True, False, True, False, False, True, True, False, False, True, True, True, True, True, False, False, False, True, False, False, True, True, False, True, True, True, False, True, True, False, False, True, False, False, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, False, False, True, False, True, True, False, False, True, True, True, True, False, False, False, False, False, False, True, True, True, True, False, True, True, False, True, False, False, True, True, True, True, True, True, True, False, False, False, True, False, True, True, True, False, False, False, False, False, False, False, False, True, True, False, False, False, True, False, False, False, False, True, True, False, False, False, True, True, True, True, True, False, False, True, True, False, False, False, True, True, True, False, False, False, False, False, True, True, False, True, True, False, False, True, False, False, False, True, True, False, False, True, True, True, True, False, False, False, False, False, False, False, False, True, True, False, False, False, True, True, True, True, False, True, False, False, True, True, True, False, False, True, True, True, True, False, False, True, True, False, True, False, True, False, True, True, False, False, True, True, False, True, False, False, False, False, False, True, True, False, True, False, True, True, False, False, False, True, True, True, False, False, False, True, True, False, True, False, True, True, False, False, True, False, False, True, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, True, True, False, False, False, False, True, False, False, False, False, False, False, True, False, False, True, False, False, False, True, True, True, True, False, False, True, True, True, True, True, False, False, True, True, True, False, True, False, False, False, False, True, True, False, False, False, True, False, True, True, True, True, False, False, True, False, False, True, True, True, False, False, False, True, False, False, False, False, True, True, True, True, False, True, True, False, False, True, True, True, False, False, False, False, False, False, True, True, True, True, False, True, True, False, True, False, False, True, False, False, True, True, False, True, False, False, True, True, True, True, True, True, False, False, False, False, True, True, False, False, True, True, False, False, True, True, True, False, False, True, False, True, True, False, False, False, False, False, False, True, True, False, True, True, False, False, False, False, True, True, True, False, False, True, False, True, True, True, True, False, False, False, True, False, True, True, True, True, True, True, True, False, True, False, False, True, False, True, True, True, False, True, True, True, False, False, True, False, False, False, True, True, True, False, False, True, True, True, False, True, False, True, True, True, False, False, False, True, False, False, True, False, True, False, False, False, False, True, False, True, False, False, False, True, True, True, True, False, True, False, True, False, True, True, True, False, False, True, True, True, False, False, False, False, True, False, False, False, False, False, True, False, False, True, True, True, False, True, True, True, True, False, False, False, True, False, True, False, True, False, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, False, False, False, False, True, True, True, False, False, True, True, False, False, False, True, False, False, False, False, False, True, False, True, False, False, True, False, True, True, True, False, False, False, False, False, True, True, False, False, False, False, True, True, True, True, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, True, True, True, True, False, True, True, True, True, False, False, False, False, False, False, True, True, False, True, True, False, False, False, True, False, False, False, False, False, False, True, False, True, True, True, False, True, True, True, True, True, False, False, True, False, True, True, False, False, False, False, True, False, True, False, False, False, True, False, True, True, True, True, False, False, False, False, True, True, True, False, True, True, True, True, True, False, False, False, True, True, False, False, True, True, True, True, False, True, True, True, False, True, False, False, False, False, False, True, True, True, False, False, False, False, False, False, True, True, True, True, False, True, True, True, False, False, False, False, False, False, False, True, False, False, True, True, True, True, True, True, True, True, True, False, True, True, False, True, False, False, True, False, False, True, True, False, False, True, True, True, True, True, False, True, True, True, True, False, True, True, False, False, False, True, True, True, True, True, True, False, False, True, True, True, False, False, True, False, False, True, True, False, False, False, True, True, False, True, True, True, False, True, True, False, False, True, True, False, False, True, True, True, True, False, True, False, False, True, False, False, True, True, False, False, False, True, True, False, False, False, True, False]\n",
            "[1680478200.0, 1680479400.0, 1680479700.0, 1680480000.0, 1680480300.0, 1680480600.0, 1680480900.0, 1680486300.0, 1680493200.0, 1680498600.0, 1680500700.0, 1680501000.0, 1680507900.0, 1680509400.0, 1680509700.0, 1680510000.0, 1680510300.0, 1680514800.0, 1680515100.0, 1680518100.0, 1680519300.0, 1680519600.0, 1680519900.0, 1680521700.0, 1680522000.0, 1680523800.0, 1680525000.0, 1680525300.0, 1680528000.0, 1680528300.0, 1680533100.0, 1680533400.0, 1680533700.0, 1680534000.0, 1680534300.0, 1680534600.0, 1680539100.0, 1680541200.0, 1680554400.0, 1680554700.0, 1680555000.0, 1680561900.0, 1680565800.0, 1680566100.0, 1680566400.0, 1680566700.0, 1680569100.0, 1680573300.0, 1680576000.0, 1680581400.0, 1680584100.0, 1680584400.0, 1680584700.0, 1680585000.0, 1680585300.0, 1680586800.0, 1680587100.0, 1680590100.0, 1680592500.0, 1680592800.0, 1680593100.0, 1680602700.0, 1680603000.0, 1680606900.0, 1680609000.0, 1680611100.0, 1680611400.0, 1680611700.0, 1680612000.0, 1680612300.0, 1680613800.0, 1680615000.0, 1680615300.0, 1680615600.0, 1680619500.0, 1680620700.0, 1680624300.0, 1680628200.0, 1680632700.0, 1680633000.0, 1680658200.0, 1680659700.0, 1680666600.0, 1680666900.0, 1680667200.0, 1680667500.0, 1680667800.0, 1680668100.0, 1680668400.0, 1680668700.0, 1680683700.0, 1680684000.0, 1680684300.0, 1680686400.0, 1680701100.0, 1680701400.0, 1680701700.0, 1680702000.0, 1680702300.0, 1680705300.0, 1680705600.0, 1680711000.0, 1680712200.0, 1680721200.0, 1680721500.0, 1680721800.0, 1680722100.0, 1680737400.0, 1680737700.0, 1680738000.0, 1680738300.0, 1680740100.0, 1680740400.0, 1680743400.0, 1680743700.0, 1680744000.0, 1680748800.0, 1680749100.0, 1680753300.0, 1680754500.0, 1680757200.0, 1680766800.0, 1680767100.0, 1680768300.0, 1680769500.0, 1680769800.0, 1680770100.0, 1680770400.0, 1680770700.0, 1680774600.0, 1680774900.0, 1680775200.0, 1680780300.0, 1680784800.0, 1680797700.0, 1680800100.0, 1680808500.0, 1680812700.0, 1680813900.0, 1680821400.0, 1680828600.0, 1680832200.0, 1680832500.0, 1680838200.0, 1680843600.0, 1680843900.0, 1680850500.0, 1680850800.0, 1680851100.0, 1680851400.0, 1680851700.0, 1680857100.0, 1680858300.0, 1680862200.0, 1680862500.0, 1680862800.0, 1680863100.0, 1680866100.0, 1680867600.0, 1680867900.0, 1680868200.0, 1681080300.0, 1681080600.0, 1681080900.0, 1681081200.0, 1681081500.0, 1681081800.0, 1681082100.0, 1681086000.0, 1681086300.0, 1681086600.0, 1681086900.0, 1681097100.0, 1681097400.0, 1681099200.0, 1681099500.0, 1681099800.0, 1681103100.0, 1681105500.0, 1681105800.0, 1681109400.0, 1681109700.0, 1681110000.0, 1681115100.0, 1681123500.0, 1681125600.0, 1681125900.0, 1681126200.0, 1681128600.0, 1681128900.0, 1681129200.0, 1681133700.0, 1681142100.0, 1681142400.0, 1681148400.0, 1681155000.0, 1681159800.0, 1681160100.0, 1681164000.0, 1681166400.0, 1681170300.0, 1681173000.0, 1681173300.0, 1681184100.0, 1681184400.0, 1681184700.0, 1681188900.0, 1681197300.0, 1681199100.0, 1681209300.0, 1681209600.0, 1681209900.0, 1681211100.0, 1681211400.0, 1681217700.0, 1681218000.0, 1681220400.0, 1681220700.0, 1681221000.0, 1681222500.0, 1681224000.0, 1681225200.0, 1681236600.0, 1681241400.0, 1681241700.0, 1681242000.0, 1681242300.0, 1681242600.0, 1681262700.0, 1681266600.0, 1681271100.0, 1681272300.0, 1681279800.0, 1681280100.0, 1681282800.0, 1681283100.0, 1681283400.0, 1681284900.0, 1681288200.0, 1681288500.0, 1681288800.0, 1681290000.0, 1681292700.0, 1681294800.0, 1681295100.0, 1681295400.0, 1681295700.0, 1681296000.0, 1681303500.0, 1681305900.0, 1681306200.0, 1681306500.0, 1681306800.0, 1681307100.0, 1681307400.0, 1681307700.0, 1681311600.0, 1681311900.0, 1681312200.0, 1681321500.0, 1681324200.0, 1681324500.0, 1681327200.0, 1681327500.0, 1681329000.0, 1681371900.0, 1681372200.0, 1681373700.0, 1681378500.0, 1681378800.0, 1681380600.0, 1681380900.0, 1681381200.0, 1681385100.0, 1681386300.0, 1681386600.0, 1681386900.0, 1681387200.0, 1681391700.0, 1681392000.0, 1681398900.0, 1681404000.0, 1681404300.0, 1681404600.0, 1681410600.0, 1681419000.0, 1681419300.0, 1681427700.0, 1681428000.0, 1681428300.0, 1681433700.0, 1681434000.0, 1681434300.0, 1681438500.0, 1681438800.0, 1681440900.0, 1681444500.0, 1681444800.0, 1681446600.0, 1681446900.0, 1681447200.0, 1681448700.0, 1681458300.0, 1681459500.0, 1681459800.0, 1681460100.0, 1681463100.0, 1681464900.0, 1681470000.0, 1681470300.0, 1681490400.0, 1681490700.0, 1681493400.0, 1681499400.0, 1681499700.0, 1681505700.0, 1681684500.0, 1681686600.0, 1681686900.0, 1681692300.0, 1681692600.0, 1681692900.0, 1681693200.0, 1681696500.0, 1681696800.0, 1681697100.0, 1681697400.0, 1681712400.0, 1681713600.0, 1681715700.0, 1681722900.0, 1681723200.0, 1681724700.0, 1681730400.0, 1681730700.0, 1681739400.0, 1681745700.0, 1681746000.0, 1681747500.0, 1681747800.0, 1681748100.0, 1681748400.0, 1681753800.0, 1681754100.0, 1681763700.0, 1681764000.0, 1681764300.0, 1681764600.0, 1681764900.0, 1681774200.0, 1681775400.0, 1681776600.0, 1681776900.0, 1681785300.0, 1681787700.0, 1681791600.0, 1681803600.0, 1681806300.0, 1681815600.0, 1681822500.0, 1681822800.0, 1681823100.0, 1681823400.0, 1681826400.0, 1681828200.0, 1681838400.0, 1681838700.0, 1681843800.0, 1681859400.0, 1681860600.0, 1681862400.0, 1681867800.0, 1681868100.0, 1681869300.0, 1681869600.0, 1681877400.0, 1681877700.0, 1681880700.0, 1681884300.0, 1681884600.0, 1681884900.0, 1681885200.0, 1681889700.0, 1681890000.0, 1681894800.0, 1681895100.0, 1681896900.0, 1681897200.0, 1681897500.0, 1681897800.0, 1681903200.0, 1681904700.0, 1681910400.0, 1681911900.0, 1681912200.0, 1681914000.0, 1681917900.0, 1681918200.0, 1681926000.0, 1681926300.0, 1681932900.0, 1681933200.0, 1681933500.0, 1681936500.0, 1681942200.0, 1681942500.0, 1681942800.0, 1681944000.0, 1681946100.0, 1681947300.0, 1681947600.0, 1681951500.0, 1681956900.0, 1681957200.0, 1681959000.0, 1681960200.0, 1681965000.0, 1681965300.0, 1681965600.0, 1681967100.0, 1681967400.0, 1681968600.0, 1681972200.0, 1681972500.0, 1681976100.0, 1681976400.0, 1681977900.0, 1681979700.0, 1681980000.0, 1681991700.0, 1681992000.0, 1681992300.0, 1681992600.0, 1681994400.0, 1682000700.0, 1682002800.0, 1682003100.0, 1682012400.0, 1682012700.0, 1682013900.0, 1682014200.0, 1682014500.0, 1682014800.0, 1682015100.0, 1682015400.0, 1682015700.0, 1682016000.0, 1682016300.0, 1682018400.0, 1682018700.0, 1682039400.0, 1682039700.0, 1682043000.0, 1682047500.0, 1682050800.0, 1682055000.0, 1682055300.0, 1682058900.0, 1682059200.0, 1682059500.0, 1682065800.0, 1682067900.0, 1682070900.0, 1682071200.0, 1682072700.0, 1682073000.0, 1682073300.0, 1682074500.0, 1682084100.0, 1682085300.0, 1682085600.0, 1682088300.0, 1682097600.0, 1682102100.0, 1682102400.0, 1682102700.0, 1682103000.0, 1682104200.0, 1682108400.0, 1682108700.0, 1682294400.0, 1682294700.0, 1682304000.0, 1682304300.0, 1682304600.0, 1682312400.0, 1682312700.0, 1682314800.0, 1682322600.0, 1682324100.0, 1682324400.0, 1682329800.0, 1682330100.0, 1682336700.0, 1682338500.0, 1682342400.0, 1682342700.0, 1682345100.0, 1682346900.0, 1682347200.0, 1682349000.0, 1682351100.0, 1682351400.0, 1682360700.0, 1682361000.0, 1682361300.0, 1682368500.0, 1682368800.0, 1682369100.0, 1682369400.0, 1682376600.0, 1682376900.0, 1682381700.0, 1682382000.0, 1682382300.0, 1682384100.0, 1682386800.0, 1682387100.0, 1682387400.0, 1682387700.0, 1682388000.0, 1682390700.0, 1682393400.0, 1682393700.0, 1682394900.0, 1682400300.0, 1682403300.0, 1682403600.0, 1682410800.0, 1682417700.0, 1682422500.0, 1682422800.0, 1682431800.0, 1682432100.0, 1682432400.0, 1682436600.0, 1682436900.0, 1682437200.0, 1682438400.0, 1682440500.0, 1682442900.0, 1682443200.0, 1682446200.0, 1682446500.0, 1682449200.0, 1682451900.0, 1682463000.0, 1682463300.0, 1682463600.0, 1682467200.0, 1682473800.0, 1682478600.0, 1682479800.0, 1682481600.0, 1682481900.0, 1682482200.0, 1682489400.0, 1682489700.0, 1682491500.0, 1682500200.0, 1682503800.0, 1682506800.0, 1682507100.0, 1682507400.0, 1682518800.0, 1682526900.0, 1682528100.0, 1682531100.0, 1682531400.0, 1682532600.0, 1682532900.0, 1682534400.0, 1682548800.0, 1682550600.0, 1682550900.0, 1682553900.0, 1682556000.0, 1682556300.0, 1682556600.0, 1682567100.0, 1682582700.0, 1682589300.0, 1682589600.0, 1682589900.0, 1682598900.0, 1682599200.0, 1682607300.0, 1682621100.0, 1682623800.0, 1682624100.0, 1682624400.0, 1682626500.0, 1682628600.0, 1682628900.0, 1682632800.0, 1682640300.0, 1682647500.0, 1682650800.0, 1682651100.0, 1682657100.0, 1682661900.0, 1682669100.0, 1682670600.0, 1682679000.0, 1682682900.0, 1682683200.0, 1682683500.0, 1682688900.0, 1682689200.0, 1682692800.0, 1682694000.0, 1682707200.0, 1682710200.0, 1682898000.0, 1682905500.0, 1682910600.0, 1682910900.0, 1682913900.0, 1682919600.0, 1682924400.0, 1682926200.0, 1682926500.0, 1682926800.0, 1682928600.0, 1682928900.0, 1682934300.0, 1682934600.0, 1682937600.0, 1682953800.0, 1682954100.0, 1682954400.0, 1682965200.0, 1682965500.0, 1682965800.0, 1682969700.0, 1682973600.0, 1682973900.0, 1682974200.0, 1682979000.0, 1682981100.0, 1682983200.0, 1682983500.0, 1682986800.0, 1682992200.0, 1682998200.0, 1683006600.0, 1683006900.0, 1683017400.0, 1683021300.0, 1683021600.0, 1683025200.0, 1683027000.0, 1683027300.0, 1683030000.0, 1683030300.0, 1683036000.0, 1683036300.0, 1683036600.0, 1683036900.0, 1683037200.0, 1683039300.0, 1683039600.0, 1683055500.0, 1683055800.0, 1683059400.0, 1683075900.0, 1683093900.0, 1683096000.0, 1683099900.0, 1683100200.0, 1683104100.0, 1683106500.0, 1683111000.0, 1683111300.0, 1683117600.0, 1683117900.0, 1683122700.0, 1683123000.0, 1683127800.0, 1683139800.0, 1683141000.0, 1683142500.0, 1683142800.0, 1683143100.0, 1683145200.0, 1683162000.0, 1683171900.0, 1683173100.0, 1683173400.0, 1683173700.0, 1683179100.0, 1683179400.0, 1683184200.0, 1683186600.0, 1683187800.0, 1683189000.0, 1683197100.0, 1683206400.0, 1683207600.0, 1683210000.0, 1683210300.0, 1683215400.0, 1683224400.0, 1683224700.0, 1683225000.0, 1683225300.0, 1683230400.0, 1683230700.0, 1683233100.0, 1683245700.0, 1683246000.0, 1683253800.0, 1683259800.0, 1683264900.0, 1683265200.0, 1683274500.0, 1683274800.0, 1683286800.0, 1683287100.0, 1683288900.0, 1683301200.0, 1683303000.0, 1683303300.0, 1683310500.0, 1683316500.0, 1683316800.0, 1683502500.0, 1683502800.0, 1683503100.0, 1683510600.0, 1683518100.0, 1683519300.0, 1683524700.0, 1683525000.0, 1683528900.0, 1683529200.0, 1683536400.0, 1683541800.0, 1683549600.0, 1683553200.0, 1683556200.0, 1683569100.0, 1683573000.0, 1683576000.0, 1683578100.0, 1683578400.0, 1683578700.0, 1683593100.0, 1683599400.0, 1683607500.0, 1683611400.0, 1683612600.0, 1683612900.0, 1683615300.0, 1683615600.0, 1683615900.0, 1683617700.0, 1683620100.0, 1683620400.0, 1683620700.0, 1683621000.0, 1683624000.0, 1683627300.0, 1683631500.0, 1683631800.0, 1683632100.0, 1683636000.0, 1683636300.0, 1683636600.0, 1683636900.0, 1683637200.0, 1683641400.0, 1683641700.0, 1683647700.0, 1683648000.0, 1683654300.0, 1683657000.0, 1683659700.0, 1683665700.0, 1683669600.0, 1683678600.0, 1683681300.0, 1683690900.0, 1683691200.0, 1683691500.0, 1683696600.0, 1683703800.0, 1683704100.0, 1683704400.0, 1683705900.0, 1683712800.0, 1683725100.0, 1683726300.0, 1683734400.0, 1683734700.0, 1683737400.0, 1683737700.0, 1683739200.0, 1683739500.0, 1683743100.0, 1683748500.0, 1683751200.0, 1683759000.0, 1683759300.0, 1683759600.0, 1683759900.0, 1683760200.0, 1683768600.0, 1683768900.0, 1683769200.0, 1683769500.0, 1683769800.0, 1683770100.0, 1683771900.0, 1683780900.0, 1683781200.0, 1683781500.0, 1683781800.0, 1683785700.0, 1683789600.0, 1683792000.0, 1683796500.0, 1683798900.0, 1683800100.0, 1683803100.0, 1683803400.0, 1683803700.0, 1683804000.0, 1683805200.0, 1683810300.0, 1683843600.0, 1683843900.0, 1683851100.0, 1683855300.0, 1683858600.0, 1683877800.0, 1683878100.0, 1683878400.0, 1683885000.0, 1683885300.0, 1683892500.0, 1683892800.0, 1683894000.0, 1683894300.0, 1683896400.0, 1683904500.0, 1683904800.0, 1683905100.0, 1683905400.0, 1683905700.0, 1683906000.0, 1683907800.0, 1683909900.0, 1683910200.0, 1683912900.0, 1683914100.0, 1683922200.0, 1684101900.0, 1684104300.0, 1684106700.0, 1684111800.0, 1684115400.0, 1684140900.0, 1684148700.0, 1684151400.0, 1684153200.0, 1684153500.0, 1684157400.0, 1684157700.0, 1684158900.0, 1684168200.0, 1684171800.0, 1684172100.0, 1684172400.0, 1684172700.0, 1684175100.0, 1684175400.0, 1684182600.0, 1684182900.0, 1684188600.0, 1684190100.0, 1684190400.0, 1684193100.0, 1684193400.0, 1684193700.0, 1684194000.0, 1684203000.0, 1684209600.0, 1684213200.0, 1684214400.0, 1684224300.0, 1684225800.0, 1684226100.0, 1684226400.0, 1684228500.0, 1684228800.0, 1684229100.0, 1684235700.0, 1684236000.0, 1684240800.0, 1684241100.0, 1684241400.0, 1684241700.0, 1684246200.0, 1684254000.0, 1684260600.0, 1684266000.0, 1684266300.0, 1684266600.0, 1684266900.0, 1684276200.0, 1684276500.0, 1684276800.0, 1684280100.0, 1684280400.0, 1684295700.0, 1684301400.0, 1684303500.0, 1684308000.0, 1684308300.0, 1684308600.0, 1684313100.0, 1684313400.0, 1684314600.0, 1684316400.0, 1684318200.0, 1684318500.0, 1684318800.0, 1684325400.0, 1684325700.0, 1684326000.0, 1684329000.0, 1684329300.0, 1684331400.0, 1684331700.0, 1684339800.0, 1684340100.0, 1684351800.0, 1684353600.0, 1684356600.0, 1684356900.0, 1684363200.0, 1684364400.0, 1684370400.0, 1684370700.0, 1684373700.0, 1684374000.0, 1684382100.0, 1684382400.0, 1684391700.0, 1684392000.0, 1684392300.0, 1684392600.0, 1684398300.0, 1684398600.0, 1684398900.0, 1684403700.0, 1684411500.0, 1684411800.0, 1684412100.0, 1684412400.0, 1684414500.0, 1684425900.0, 1684426200.0, 1684432800.0, 1684433100.0, 1684448700.0, 1684456500.0, 1684467300.0, 1684467600.0, 1684475400.0, 1684475700.0, 1684476000.0, 1684478400.0, 1684478700.0, 1684479000.0, 1684479300.0, 1684479600.0, 1684479900.0, 1684488000.0, 1684491300.0, 1684493400.0, 1684498500.0, 1684507500.0, 1684510500.0, 1684512000.0, 1684512300.0, 1684512600.0, 1684513800.0, 1684517700.0, 1684518000.0, 1684518300.0, 1684519500.0, 1684519800.0, 1684524300.0, 1684526700.0, 1684527000.0, 1684527300.0, 1684721400.0, 1684731600.0, 1684731900.0, 1684733700.0, 1684735200.0, 1684747800.0, 1684749000.0, 1684749300.0, 1684751100.0, 1684751400.0, 1684752600.0, 1684753800.0, 1684759800.0, 1684764300.0, 1684769700.0, 1684770000.0, 1684770300.0, 1684772700.0, 1684773000.0, 1684778100.0, 1684783500.0, 1684783800.0, 1684784100.0, 1684787100.0, 1684813500.0, 1684821900.0, 1684822200.0, 1684824900.0, 1684825200.0, 1684827300.0, 1684835100.0, 1684839000.0, 1684840200.0, 1684842000.0, 1684842300.0, 1684842600.0, 1684842900.0, 1684847700.0, 1684848000.0, 1684848300.0, 1684852200.0, 1684853400.0, 1684859700.0, 1684860000.0, 1684860300.0, 1684863000.0, 1684865700.0, 1684866000.0, 1684890900.0, 1684893300.0, 1684893600.0, 1684893900.0, 1684898700.0, 1684907100.0, 1684907400.0, 1684907700.0, 1684908000.0, 1684914000.0, 1684923300.0, 1684923600.0, 1684923900.0, 1684924200.0, 1684926600.0, 1684932900.0, 1684933200.0, 1684933500.0, 1684935900.0, 1684936200.0, 1684939500.0, 1684939800.0, 1684945200.0, 1684945500.0, 1684948200.0, 1684967100.0, 1684967400.0, 1684967700.0, 1684972800.0, 1684977300.0, 1684977600.0, 1684977900.0, 1684982700.0, 1684989000.0, 1684989300.0, 1684991700.0, 1684994100.0, 1684994400.0, 1684998300.0, 1684998600.0, 1685000400.0, 1685010900.0, 1685011200.0, 1685011500.0, 1685017800.0, 1685021700.0, 1685024100.0, 1685024400.0, 1685028900.0, 1685029200.0, 1685033700.0, 1685039400.0, 1685039700.0, 1685040000.0, 1685040300.0, 1685044500.0, 1685059500.0, 1685068200.0, 1685075400.0, 1685082900.0, 1685084700.0, 1685086800.0, 1685091900.0, 1685092200.0, 1685107500.0, 1685113500.0, 1685121900.0, 1685129100.0, 1685130900.0, 1685312100.0, 1685319900.0, 1685320200.0, 1685323800.0, 1685343000.0, 1685352600.0, 1685352900.0, 1685358000.0, 1685358300.0, 1685358600.0, 1685402700.0, 1685412300.0, 1685444100.0, 1685447100.0, 1685449500.0, 1685449800.0, 1685454600.0, 1685462400.0, 1685462700.0, 1685463000.0, 1685463300.0, 1685467500.0, 1685469600.0, 1685474100.0, 1685474400.0, 1685475900.0, 1685476200.0, 1685493000.0, 1685495400.0, 1685498700.0, 1685499000.0, 1685502300.0, 1685507100.0, 1685509200.0, 1685509500.0, 1685513100.0, 1685513400.0, 1685516400.0, 1685519400.0, 1685521800.0, 1685522100.0, 1685526900.0, 1685533500.0, 1685533800.0, 1685542500.0, 1685542800.0, 1685543100.0, 1685543400.0, 1685545500.0, 1685545800.0, 1685546100.0, 1685550300.0, 1685559000.0, 1685560200.0, 1685563200.0, 1685563500.0, 1685578500.0, 1685579700.0, 1685580000.0, 1685580300.0, 1685583600.0, 1685583900.0, 1685585700.0, 1685605800.0, 1685606100.0, 1685606400.0, 1685611200.0, 1685618700.0, 1685619000.0, 1685619300.0, 1685621700.0, 1685623500.0, 1685623800.0, 1685640300.0, 1685647500.0, 1685647800.0, 1685648100.0, 1685661000.0, 1685664600.0, 1685665800.0, 1685666100.0, 1685667900.0, 1685684700.0, 1685689500.0, 1685689800.0, 1685695500.0, 1685701800.0, 1685702100.0, 1685702400.0, 1685702700.0, 1685703000.0, 1685706000.0, 1685708100.0, 1685713500.0, 1685713800.0, 1685714100.0, 1685720100.0, 1685722200.0, 1685722500.0, 1685727600.0, 1685727900.0, 1685728200.0, 1685729400.0, 1685734200.0, 1685919900.0, 1685920200.0, 1685920500.0, 1685928300.0, 1685928600.0, 1685936700.0, 1685946900.0, 1685951400.0, 1685951700.0, 1685956500.0, 1685958000.0, 1685964300.0, 1685964600.0, 1685964900.0, 1685965200.0, 1685987100.0, 1685987400.0, 1685994900.0, 1686002400.0, 1686002700.0, 1686003000.0, 1686003300.0, 1686004500.0, 1686004800.0, 1686005100.0, 1686008700.0, 1686010200.0, 1686010500.0, 1686010800.0, 1686014700.0, 1686015000.0, 1686020700.0, 1686027300.0, 1686030600.0, 1686030900.0, 1686031200.0, 1686033600.0, 1686033900.0, 1686034200.0, 1686040200.0, 1686052500.0, 1686054600.0, 1686054900.0, 1686060000.0, 1686069900.0, 1686074400.0, 1686080100.0, 1686082500.0, 1686082800.0, 1686090300.0, 1686091800.0, 1686092100.0, 1686095100.0, 1686096300.0, 1686099600.0, 1686099900.0, 1686103500.0, 1686103800.0, 1686116700.0, 1686117000.0, 1686120000.0, 1686120300.0, 1686123900.0, 1686136800.0, 1686139800.0, 1686147600.0, 1686147900.0, 1686148200.0, 1686148500.0, 1686148800.0, 1686149100.0, 1686149400.0, 1686154800.0, 1686155100.0, 1686156900.0, 1686157200.0, 1686162600.0, 1686165000.0, 1686166500.0, 1686170400.0, 1686177000.0, 1686177300.0, 1686177600.0, 1686180300.0, 1686188400.0, 1686190200.0, 1686190500.0, 1686191700.0, 1686192000.0, 1686194700.0, 1686195000.0, 1686196800.0, 1686197100.0, 1686198900.0, 1686199200.0, 1686204600.0, 1686211200.0, 1686229200.0, 1686229500.0, 1686229800.0, 1686230100.0, 1686244800.0, 1686245100.0, 1686245400.0, 1686245700.0, 1686246000.0, 1686246300.0, 1686265800.0, 1686269100.0, 1686271800.0, 1686277200.0, 1686283200.0, 1686283500.0, 1686303600.0, 1686303900.0, 1686304200.0, 1686307200.0, 1686321000.0, 1686321300.0, 1686321600.0, 1686321900.0, 1686322200.0, 1686324300.0, 1686324600.0, 1686326100.0, 1686335700.0, 1686339600.0, 1686339900.0, 1686340200.0, 1686343200.0, 1686343500.0, 1686343800.0, 1686344100.0, 1686520800.0, 1686527100.0, 1686531300.0, 1686531600.0, 1686531900.0, 1686532200.0, 1686548100.0, 1686548400.0, 1686548700.0, 1686562800.0, 1686563100.0, 1686563400.0, 1686564600.0, 1686564900.0, 1686565200.0, 1686565500.0, 1686576000.0, 1686577800.0, 1686582000.0, 1686582300.0, 1686612900.0, 1686613200.0, 1686613500.0, 1686615900.0, 1686635100.0, 1686638700.0, 1686639900.0, 1686640200.0, 1686642900.0, 1686643200.0, 1686648000.0, 1686648300.0, 1686648600.0, 1686648900.0, 1686649200.0, 1686653100.0, 1686655800.0, 1686656100.0, 1686656400.0, 1686656700.0, 1686657000.0, 1686662400.0, 1686662700.0, 1686663900.0, 1686670800.0, 1686678900.0, 1686679200.0, 1686679500.0, 1686680700.0, 1686684600.0, 1686697800.0, 1686698100.0, 1686698400.0, 1686701100.0, 1686701400.0, 1686702600.0, 1686708000.0, 1686708300.0, 1686708600.0, 1686715800.0, 1686723300.0, 1686723600.0, 1686725100.0, 1686739800.0, 1686746100.0, 1686754800.0, 1686758400.0, 1686760200.0, 1686760500.0, 1686760800.0, 1686761100.0, 1686762600.0, 1686762900.0, 1686765600.0, 1686765900.0, 1686780000.0, 1686780300.0, 1686780600.0, 1686780900.0, 1686783900.0, 1686787200.0, 1686790200.0, 1686791700.0, 1686792000.0, 1686805200.0, 1686807900.0, 1686808200.0, 1686808500.0, 1686808800.0, 1686810900.0, 1686816300.0, 1686816600.0, 1686817800.0, 1686818100.0, 1686818400.0, 1686821100.0, 1686823800.0, 1686827700.0, 1686847800.0, 1686849000.0, 1686852900.0, 1686858000.0, 1686859200.0, 1686873900.0, 1686874200.0, 1686875400.0, 1686878700.0, 1686879000.0, 1686880800.0, 1686885300.0, 1686889800.0, 1686890100.0, 1686891300.0, 1686891600.0, 1686891900.0, 1686899100.0, 1686899400.0, 1686907200.0, 1686907500.0, 1686907800.0, 1686909900.0, 1686910200.0, 1686910500.0, 1686922800.0, 1686926400.0, 1686926700.0, 1686929100.0, 1686931800.0, 1686935100.0, 1686935400.0, 1686935700.0, 1686942300.0, 1686942600.0, 1687126500.0, 1687138200.0, 1687146000.0, 1687146300.0, 1687146600.0, 1687146900.0, 1687147200.0, 1687160700.0, 1687163400.0, 1687163700.0, 1687171500.0, 1687175400.0, 1687175700.0, 1687176000.0, 1687176300.0, 1687178700.0, 1687179900.0, 1687181100.0, 1687181400.0, 1687181700.0, 1687187100.0, 1687192200.0, 1687214700.0, 1687227900.0, 1687238100.0, 1687238400.0, 1687238700.0, 1687239000.0, 1687242900.0, 1687243200.0, 1687244400.0, 1687248600.0, 1687248900.0, 1687249200.0, 1687249500.0, 1687249800.0, 1687264500.0, 1687270500.0, 1687270800.0, 1687271100.0, 1687276800.0, 1687286400.0, 1687291200.0, 1687291500.0, 1687293600.0, 1687299300.0, 1687309500.0, 1687314900.0, 1687315200.0, 1687315500.0, 1687318200.0, 1687318500.0, 1687323900.0, 1687325400.0, 1687329900.0, 1687338000.0, 1687338300.0, 1687347300.0, 1687349100.0, 1687349400.0, 1687355400.0, 1687355700.0, 1687356000.0, 1687356300.0, 1687358700.0, 1687373100.0, 1687375800.0, 1687376100.0, 1687380900.0, 1687385700.0, 1687386000.0, 1687386300.0, 1687389600.0, 1687389900.0, 1687393800.0, 1687394100.0, 1687394400.0, 1687396500.0, 1687396800.0, 1687397100.0, 1687397400.0, 1687404300.0, 1687407000.0, 1687410300.0, 1687411800.0, 1687421100.0, 1687421400.0, 1687428600.0, 1687428900.0, 1687430100.0, 1687430400.0, 1687430700.0, 1687431000.0, 1687437900.0, 1687438200.0, 1687438500.0, 1687444800.0, 1687450200.0, 1687452300.0, 1687452600.0, 1687461900.0, 1687471500.0, 1687471800.0, 1687475100.0, 1687476300.0, 1687476600.0, 1687478100.0, 1687478400.0, 1687479600.0, 1687479900.0, 1687480200.0, 1687482000.0, 1687484100.0, 1687484400.0, 1687484700.0, 1687485900.0, 1687493700.0, 1687494000.0, 1687494300.0, 1687496100.0, 1687496400.0, 1687505400.0, 1687508400.0, 1687508700.0, 1687510200.0, 1687510500.0, 1687516500.0, 1687521000.0, 1687521300.0, 1687521600.0, 1687521900.0, 1687523700.0, 1687524000.0, 1687524300.0, 1687527900.0, 1687533600.0, 1687533900.0, 1687534200.0, 1687545300.0, 1687545600.0, 1687545900.0, 1687546200.0, 1687546500.0, 1687546800.0, 1687550100.0, 1687551300.0, 1687736400.0, 1687736700.0, 1687737000.0, 1687740300.0, 1687741800.0, 1687744500.0, 1687750800.0, 1687755000.0, 1687755300.0, 1687755600.0, 1687759200.0, 1687761300.0, 1687761600.0, 1687763400.0, 1687763700.0, 1687776900.0, 1687777200.0, 1687781100.0, 1687783500.0, 1687783800.0, 1687790400.0, 1687791900.0, 1687792200.0, 1687792500.0, 1687797300.0, 1687797600.0, 1687797900.0, 1687799400.0, 1687801200.0, 1687805400.0, 1687805700.0, 1687807200.0, 1687808700.0, 1687809000.0, 1687809300.0, 1687811100.0, 1687811400.0, 1687811700.0, 1687812000.0, 1687818300.0, 1687818600.0, 1687827300.0, 1687828500.0, 1687832700.0, 1687835700.0, 1687837800.0, 1687841400.0, 1687848900.0, 1687850700.0, 1687851000.0, 1687855200.0, 1687858800.0, 1687863600.0, 1687863900.0, 1687866000.0, 1687866300.0, 1687866600.0, 1687870200.0, 1687878300.0, 1687885200.0, 1687885500.0, 1687896000.0, 1687896300.0, 1687903500.0, 1687903800.0, 1687904100.0, 1687906200.0, 1687908000.0, 1687911600.0, 1687911900.0, 1687912200.0, 1687912500.0, 1687918500.0, 1687918800.0, 1687920900.0, 1687925100.0, 1687926300.0, 1687928700.0, 1687934700.0, 1687941300.0, 1687941600.0, 1687941900.0, 1687944000.0, 1687951800.0, 1687953000.0, 1687953300.0, 1687953600.0, 1687956000.0, 1687958100.0, 1687969800.0, 1687970100.0, 1687970400.0, 1687979100.0, 1687995600.0, 1687995900.0, 1687997100.0, 1688002800.0, 1688003100.0, 1688004300.0, 1688007300.0, 1688007600.0, 1688007900.0, 1688014200.0, 1688014500.0, 1688016000.0, 1688016300.0, 1688030400.0, 1688036400.0, 1688038800.0, 1688042400.0, 1688042700.0, 1688043000.0, 1688044800.0, 1688054700.0, 1688055000.0, 1688057700.0, 1688058000.0, 1688060100.0, 1688060400.0, 1688061900.0, 1688066100.0, 1688066400.0, 1688072100.0, 1688076000.0, 1688083500.0, 1688083800.0, 1688091300.0, 1688093700.0, 1688100000.0, 1688106000.0, 1688110200.0, 1688113500.0, 1688116500.0, 1688119200.0, 1688123700.0, 1688129400.0, 1688136300.0, 1688138700.0, 1688139000.0, 1688139300.0, 1688139600.0, 1688145600.0, 1688148600.0, 1688151000.0, 1688151300.0, 1688151600.0, 1688156400.0, 1688336100.0, 1688336400.0, 1688336700.0, 1688337000.0, 1688363100.0, 1688374500.0, 1688374800.0, 1688375100.0, 1688375400.0, 1688375700.0, 1688376000.0, 1688379000.0, 1688382900.0, 1688392800.0, 1688394900.0, 1688427300.0, 1688434200.0, 1688436600.0, 1688446200.0, 1688446500.0, 1688449800.0, 1688480100.0, 1688480400.0, 1688480700.0, 1688481000.0, 1688481300.0, 1688486100.0, 1688486400.0, 1688488800.0, 1688489100.0, 1688489400.0, 1688489700.0, 1688522700.0, 1688523000.0, 1688525400.0, 1688526600.0, 1688529600.0, 1688536200.0, 1688536500.0, 1688536800.0, 1688537100.0, 1688537400.0, 1688537700.0, 1688538000.0, 1688538300.0, 1688539500.0, 1688539800.0, 1688540100.0, 1688548500.0, 1688548800.0, 1688549100.0, 1688549400.0, 1688549700.0, 1688550000.0, 1688555100.0, 1688555400.0, 1688558100.0, 1688558400.0, 1688568600.0, 1688570400.0, 1688581200.0, 1688586000.0, 1688587200.0, 1688587500.0, 1688595900.0, 1688600400.0, 1688601600.0, 1688601900.0, 1688602200.0, 1688604600.0, 1688604900.0, 1688605200.0, 1688611500.0, 1688612700.0, 1688613000.0, 1688614200.0, 1688614500.0, 1688615700.0, 1688616000.0, 1688616300.0, 1688616600.0, 1688616900.0, 1688619900.0, 1688621700.0, 1688622000.0, 1688624400.0, 1688625600.0, 1688627100.0, 1688634000.0, 1688637900.0, 1688640600.0, 1688643600.0, 1688643900.0, 1688646900.0, 1688647200.0, 1688647500.0, 1688670300.0, 1688670600.0, 1688670900.0, 1688674800.0, 1688675100.0, 1688675400.0, 1688675700.0, 1688676000.0, 1688676300.0, 1688686800.0, 1688693100.0, 1688693400.0, 1688693700.0, 1688694000.0, 1688700600.0, 1688700900.0, 1688701200.0, 1688703600.0, 1688705700.0, 1688707500.0, 1688707800.0, 1688711400.0, 1688721900.0, 1688722200.0, 1688722500.0, 1688736900.0, 1688739900.0, 1688740200.0, 1688752500.0, 1688752800.0, 1688755200.0, 1688755500.0, 1688756700.0, 1688757900.0, 1688759100.0, 1688759400.0, 1688759700.0, 1688761200.0, 1688762400.0, 1688762700.0, 1688940600.0, 1688942100.0, 1688945400.0, 1688948400.0, 1688948700.0, 1688949000.0, 1688953200.0, 1688958900.0, 1688959200.0, 1688966400.0, 1688966700.0, 1688967000.0, 1688967300.0, 1688967600.0, 1688967900.0, 1688978100.0, 1688979300.0, 1688981100.0, 1688991600.0, 1688991900.0, 1688992200.0, 1688992500.0, 1688992800.0, 1688993100.0, 1688993400.0, 1688997000.0, 1688997300.0, 1689003900.0, 1689005100.0, 1689005400.0, 1689014400.0, 1689016200.0, 1689020400.0, 1689020700.0, 1689021000.0, 1689021300.0, 1689022500.0, 1689026400.0, 1689026700.0, 1689030000.0, 1689039300.0, 1689048300.0, 1689062100.0, 1689062400.0, 1689071100.0, 1689072900.0, 1689077700.0, 1689081600.0, 1689081900.0, 1689084600.0, 1689092100.0, 1689095700.0, 1689096000.0, 1689099000.0, 1689099300.0, 1689099600.0, 1689117600.0, 1689117900.0, 1689121200.0, 1689124800.0, 1689125100.0, 1689125400.0, 1689136800.0, 1689137100.0, 1689137400.0, 1689144300.0, 1689145800.0, 1689148800.0, 1689150000.0, 1689156000.0, 1689156300.0, 1689164400.0, 1689166200.0, 1689172200.0, 1689173700.0, 1689174000.0, 1689174300.0, 1689175800.0, 1689176100.0, 1689176400.0, 1689187800.0, 1689188100.0, 1689191400.0, 1689191700.0, 1689203400.0, 1689216000.0, 1689223800.0, 1689224100.0, 1689224400.0, 1689224700.0, 1689230700.0, 1689240600.0, 1689240900.0, 1689241200.0, 1689245700.0, 1689246900.0, 1689247200.0, 1689267900.0, 1689270600.0, 1689278100.0, 1689278400.0, 1689280200.0, 1689288300.0, 1689291600.0, 1689291900.0, 1689294300.0, 1689305400.0, 1689306900.0, 1689307200.0, 1689311100.0, 1689315000.0, 1689315300.0, 1689322800.0, 1689323100.0, 1689327600.0, 1689327900.0, 1689328200.0, 1689328500.0, 1689331500.0, 1689338400.0, 1689339900.0, 1689345900.0, 1689351000.0, 1689351300.0, 1689351600.0, 1689353400.0, 1689353700.0, 1689354000.0, 1689354300.0, 1689358800.0, 1689359100.0, 1689359400.0, 1689359700.0, 1689363900.0, 1689366300.0, 1689366600.0, 1689366900.0, 1689367200.0, 1689558000.0]\n",
            "834.75\n",
            "\n",
            "\n",
            "0.5207014125669751\n",
            "2053\n"
          ]
        }
      ],
      "source": [
        "                                                      #variables and explinations\n",
        "#create an empty array to store values in\n",
        "array = []\n",
        "array.clear()\n",
        "\n",
        "#the max percent of correct predictions\n",
        "max_percent = 0\n",
        "\n",
        "#the rsi value this max percent occured at\n",
        "best_rsi = 0\n",
        "best_array = []\n",
        "\n",
        "#under the simulation how much money would be made\n",
        "money_made_per_cycle = 0\n",
        "total_money_made = 0\n",
        "\n",
        "#the timestamp of the occuring pattern for checking if the program functions\n",
        "timestamp = []\n",
        "timestamp.clear()\n",
        "\n",
        "#the number of candles to hold after buying\n",
        "hold_length_tuner = 2\n",
        "                                                                                       #optimization for rsi\n",
        "#the rsi runer runs through 30-70 to determine the best rsi threshold\n",
        "for rsi_tuner in range (99,100):\n",
        "\n",
        "  #runs a loop through each value in the dataset other than the first 3 days\n",
        "  numbers = iter(range(2,len(rsi)))\n",
        "  for i in numbers:\n",
        "    #if rsi is less than threshhold, the price change today is positive,\n",
        "    #the price change yesterday was negative\n",
        "    #and the price change of the day before yesterday was negative\n",
        "    if rsi[i] <= rsi_tuner and change[i] < 0 and change[i-1] < 0 and change[i-2] < 0 and (i+hold_length_tuner+1)<len(rsi)-15:\n",
        "\n",
        "      cash_flow_change = open[i+1+hold_length_tuner]-open[i+1] #the number represents the number of days/30 mins/5 min cycles held\n",
        "\n",
        "      if cash_flow_change > 0:\n",
        "        array.append(True) #True if the function made money\n",
        "\n",
        "      else:\n",
        "        array.append(False)#False if the function lost money\n",
        "\n",
        "      timestamp.append(time[i])\n",
        "      money_made_per_cycle += cash_flow_change\n",
        "      #consume(numbers, hold_length_tuner+1) #skips next three days of the inner for loop\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(rsi_tuner)\n",
        "  print((array.count(True)/(array.count(True)+array.count(False)))*100)\n",
        "  sum_of_all_percentages += (array.count(True)/(array.count(True)+array.count(False)))*100\n",
        "  print(array)\n",
        "  print(timestamp)\n",
        "  print(money_made_per_cycle)\n",
        "  print(\"\\n\")\n",
        "  print(array.count(True)/len(array))\n",
        "  print(len(array))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #this code determines the max/best values based on percent of times the function made moeny\n",
        "  # if (array.count(True)+array.count(False)) != 0: #makes sure denominator isnt 0\n",
        "  #   if (array.count(True)/(array.count(True)+array.count(False))) > max_percent and len(array) >10:\n",
        "  #     max_percent = (array.count(True)/(array.count(True)+array.count(False))) #finds max percent\n",
        "  #     best_rsi = rsi_tuner                                                     #stores best rsi threshold in a variable\n",
        "  #     best_array = array.copy()                                                #stores the array for the best rsi threshold\n",
        "  #     best_timestamp = timestamp.copy()                                        #stores the current timestamp when money is maximized\n",
        "  #     total_money_made = money_made_per_cycle                                  #stores the total money made in one cycle\n",
        "\n",
        "#  this code determines the max/best values based on the total amount of money the function made.\n",
        "  # if money_made_per_cycle > total_money_made:\n",
        "  #     max_percent = (array.count(True)/(array.count(True)+array.count(False))) #finds max percent\n",
        "  #     best_rsi = rsi_tuner                                                     #stores best rsi threshold in a variable\n",
        "  #     best_array = array.copy()                                                #stores the array for the best rsi threshold\n",
        "  #     best_timestamp = timestamp.copy()                                        #stores the current timestamp when money is maximized\n",
        "  #     total_money_made = money_made_per_cycle                                  #stores the total money made in one cycle\n",
        "\n",
        " # clears variables after 1 cycle of rsi change\n",
        "  array.clear()\n",
        "  timestamp.clear()\n",
        "  money_made_per_cycle = 0\n",
        "\n",
        "# best_timestamp = [int(x) for x in best_timestamp] #changes float into int\n",
        "\n",
        "# print(best_rsi)\n",
        "# print(max_percent*100)\n",
        "# print(best_array)\n",
        "# print(best_timestamp)\n",
        "# print(total_money_made)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#probability trading\n",
        "arr = [True, True, False, False, False] #input value, left is most recent\n",
        "current_rsi = 58\n",
        " #input value\n",
        "\n",
        "#create an empty array to store valu|es in\n",
        "array = []\n",
        "array.clear()\n",
        "\n",
        "#the number of candles to hold after buying\n",
        "\n",
        "for hold_length_tuner in range(1,6):\n",
        "  print(\"\\n\\n\")\n",
        "  print(\"HOLD FOR \" + str(hold_length_tuner) + \" INTERVALS\")                                                                                    #optimization for rsi\n",
        "  #the rsi runer runs through 30-70 to determine the best rsi threshold\n",
        "  array.clear()\n",
        "  for rsi_tuner in range (current_rsi,current_rsi+1):\n",
        "\n",
        "    #runs a loop through each value in the dataset other than the first 3 days\n",
        "    numbers = iter(range(4,len(rsi)))\n",
        "    for i in numbers:\n",
        "      #if rsi is less than threshhold, the price change today is positive,\n",
        "      #the price change yesterday was negative\n",
        "      #and the price change of the day before yesterday was negative\n",
        "      if arr[0] is True:\n",
        "        inequality_1 = change[i] > 0\n",
        "      else:\n",
        "        inequality_1 = change[i] < 0\n",
        "      if arr[1] is True:\n",
        "        inequality_2 = change[i-1] > 0\n",
        "      else:\n",
        "        inequality_2 = change[i-1] < 0\n",
        "      if arr[2] is True:\n",
        "        inequality_3 = change[i-2] > 0\n",
        "      else:\n",
        "        inequality_3 = change[i-2] < 0\n",
        "      if arr[3] is True:\n",
        "        inequality_4 = change[i-3] > 0\n",
        "      else:\n",
        "        inequality_4 = change[i-3] < 0\n",
        "      if arr[4] is True:\n",
        "        inequality_5 = change[i-4] > 0\n",
        "      else:\n",
        "        inequality_5 = change[i-4] < 0\n",
        "      if rsi[i] <= rsi_tuner+5 and inequality_1 and inequality_2 and inequality_3 and inequality_4 and inequality_5 and (i+hold_length_tuner+1)<len(rsi)-15 and rsi[i] >= rsi_tuner-5:\n",
        "\n",
        "        cash_flow_change = open[i+1+hold_length_tuner]-open[i+1] #the number represents the number of days/30 mins/5 min cycles held\n",
        "\n",
        "        if cash_flow_change > 0:\n",
        "          array.append(True) #True if the function made money\n",
        "\n",
        "        else:\n",
        "          array.append(False)#False if the function lost money\n",
        "        consume(numbers, hold_length_tuner+1) #skips next three days of the inner for loop\n",
        "    print(str(rsi_tuner) + \" rsi\")\n",
        "    print(\"PAST 5 candles\")\n",
        "    print((array.count(True)/(array.count(True)+array.count(False)))*100)\n",
        "    print(\"occured \" + str(len(array)) + \" times out of 20500\")\n",
        "    array = []\n",
        "    array.clear()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for rsi_tuner in range (current_rsi,current_rsi+1):\n",
        "\n",
        "    #runs a loop through each value in the dataset other than the first 3 days\n",
        "    numbers = iter(range(3,len(rsi)))\n",
        "    for i in numbers:\n",
        "      #if rsi is less than threshhold, the price change today is positive,\n",
        "      #the price change yesterday was negative\n",
        "      #and the price change of the day before yesterday was negative\n",
        "      if arr[0] is True:\n",
        "        inequality_1 = change[i] > 0\n",
        "      else:\n",
        "        inequality_1 = change[i] < 0\n",
        "      if arr[1] is True:\n",
        "        inequality_2 = change[i-1] > 0\n",
        "      else:\n",
        "        inequality_2 = change[i-1] < 0\n",
        "      if arr[2] is True:\n",
        "        inequality_3 = change[i-2] > 0\n",
        "      else:\n",
        "        inequality_3 = change[i-2] < 0\n",
        "      if arr[3] is True:\n",
        "        inequality_4 = change[i-3] > 0\n",
        "      else:\n",
        "        inequality_4 = change[i-3] < 0\n",
        "      if rsi[i] <= rsi_tuner+5 and inequality_1 and inequality_2 and inequality_3 and inequality_4 and (i+hold_length_tuner+1)<len(rsi)-15 and rsi[i] >= rsi_tuner-5:\n",
        "\n",
        "        cash_flow_change = open[i+1+hold_length_tuner]-open[i+1] #the number represents the number of days/30 mins/5 min cycles held\n",
        "\n",
        "        if cash_flow_change > 0:\n",
        "          array.append(True) #True if the function made money\n",
        "\n",
        "        else:\n",
        "          array.append(False)#False if the function lost money\n",
        "        consume(numbers, hold_length_tuner+1) #skips next three days of the inner for loop\n",
        "\n",
        "\n",
        "    print(\"PAST 4 candles\")\n",
        "    print((array.count(True)/(array.count(True)+array.count(False)))*100)\n",
        "    print(\"occured \" + str(len(array)) + \" times out of 20500\")\n",
        "\n",
        "    array = []\n",
        "    array.clear()\n",
        "\n",
        "\n",
        "    #the rsi runer runs through 30-70 to determine the best rsi threshold\n",
        "  for rsi_tuner in range (current_rsi,current_rsi+1):\n",
        "\n",
        "    #runs a loop through each value in the dataset other than the first 3 days\n",
        "    numbers = iter(range(3,len(rsi)))\n",
        "    for i in numbers:\n",
        "      #if rsi is less than threshhold, the price change today is positive,\n",
        "      #the price change yesterday was negative\n",
        "      #and the price change of the day before yesterday was negative\n",
        "      if arr[0] is True:\n",
        "        inequality_1 = change[i] > 0\n",
        "      else:\n",
        "        inequality_1 = change[i] < 0\n",
        "      if arr[1] is True:\n",
        "        inequality_2 = change[i-1] > 0\n",
        "      else:\n",
        "        inequality_2 = change[i-1] < 0\n",
        "      if arr[2] is True:\n",
        "        inequality_3 = change[i-2] > 0\n",
        "      else:\n",
        "        inequality_3 = change[i-2] < 0\n",
        "\n",
        "      if rsi[i] <= rsi_tuner+5 and inequality_1 and inequality_2 and inequality_3 and (i+hold_length_tuner+1)<len(rsi)-15 and rsi[i] >= rsi_tuner-5:\n",
        "\n",
        "        cash_flow_change = open[i+1+hold_length_tuner]-open[i+1] #the number represents the number of days/30 mins/5 min cycles held\n",
        "\n",
        "        if cash_flow_change > 0:\n",
        "          array.append(True) #True if the function made money\n",
        "\n",
        "        else:\n",
        "          array.append(False)#False if the function lost money\n",
        "        consume(numbers, hold_length_tuner+1) #skips next three days of the inner for loop\n",
        "\n",
        "  print(\"PAST 3 candles\")\n",
        "  print((array.count(True)/(array.count(True)+array.count(False)))*100)\n",
        "  print(\"occured \" + str(len(array)) + \" times out of 20500\")\n",
        "  array = []\n",
        "  array.clear()\n",
        "    #the rsi runer runs through 30-70 to determine the best rsi threshold\n",
        "  for rsi_tuner in range (current_rsi,current_rsi+1):\n",
        "\n",
        "    #runs a loop through each value in the dataset other than the first 3 days\n",
        "    numbers = iter(range(3,len(rsi)))\n",
        "    for i in numbers:\n",
        "      #if rsi is less than threshhold, the price change today is positive,\n",
        "      #the price change yesterday was negative\n",
        "      #and the price change of the day before yesterday was negative\n",
        "      if arr[0] is True:\n",
        "        inequality_1 = change[i] > 0\n",
        "      else:\n",
        "        inequality_1 = change[i] < 0\n",
        "      if arr[1] is True:\n",
        "        inequality_2 = change[i-1] > 0\n",
        "      else:\n",
        "        inequality_2 = change[i-1] < 0\n",
        "\n",
        "      if rsi[i] <= rsi_tuner+5 and inequality_1 and inequality_2 and (i+hold_length_tuner+1)<len(rsi)-15 and rsi[i] >= rsi_tuner-5:\n",
        "\n",
        "        cash_flow_change = open[i+1+hold_length_tuner]-open[i+1] #the number represents the number of days/30 mins/5 min cycles held\n",
        "\n",
        "        if cash_flow_change > 0:\n",
        "          array.append(True) #True if the function made money\n",
        "\n",
        "        else:\n",
        "          array.append(False)#False if the function lost money\n",
        "        consume(numbers, hold_length_tuner+1) #skips next three days of the inner for loop++\n",
        "\n",
        "  print(\"PAST 2 candles\")\n",
        "  print((array.count(True)/(array.count(True)+array.count(False)))*100)\n",
        "  print(\"occured \" + str(len(array)) + \" times out of 20500\")\n"
      ],
      "metadata": {
        "id": "t8g5IXLbTwTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78615ac2-7f4b-4ec2-d040-3abd9912e279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "HOLD FOR 1 INTERVALS\n",
            "58 rsi\n",
            "PAST 5 candles\n",
            "48.1203007518797\n",
            "occured 133 times out of 20500\n",
            "PAST 4 candles\n",
            "50.74183976261127\n",
            "occured 337 times out of 20500\n",
            "PAST 3 candles\n",
            "48.65900383141762\n",
            "occured 783 times out of 20500\n",
            "PAST 2 candles\n",
            "48.090909090909086\n",
            "occured 1100 times out of 20500\n",
            "\n",
            "\n",
            "\n",
            "HOLD FOR 2 INTERVALS\n",
            "58 rsi\n",
            "PAST 5 candles\n",
            "45.86466165413533\n",
            "occured 133 times out of 20500\n",
            "PAST 4 candles\n",
            "48.6646884272997\n",
            "occured 337 times out of 20500\n",
            "PAST 3 candles\n",
            "48.28060522696011\n",
            "occured 727 times out of 20500\n",
            "PAST 2 candles\n",
            "48.96755162241888\n",
            "occured 1017 times out of 20500\n",
            "\n",
            "\n",
            "\n",
            "HOLD FOR 3 INTERVALS\n",
            "58 rsi\n",
            "PAST 5 candles\n",
            "50.37593984962406\n",
            "occured 133 times out of 20500\n",
            "PAST 4 candles\n",
            "50.153846153846146\n",
            "occured 325 times out of 20500\n",
            "PAST 3 candles\n",
            "52.41581259150805\n",
            "occured 683 times out of 20500\n",
            "PAST 2 candles\n",
            "52.73311897106109\n",
            "occured 933 times out of 20500\n",
            "\n",
            "\n",
            "\n",
            "HOLD FOR 4 INTERVALS\n",
            "58 rsi\n",
            "PAST 5 candles\n",
            "43.18181818181818\n",
            "occured 132 times out of 20500\n",
            "PAST 4 candles\n",
            "44.479495268138805\n",
            "occured 317 times out of 20500\n",
            "PAST 3 candles\n",
            "49.31297709923664\n",
            "occured 655 times out of 20500\n",
            "PAST 2 candles\n",
            "50.726256983240226\n",
            "occured 895 times out of 20500\n",
            "\n",
            "\n",
            "\n",
            "HOLD FOR 5 INTERVALS\n",
            "58 rsi\n",
            "PAST 5 candles\n",
            "44.18604651162791\n",
            "occured 129 times out of 20500\n",
            "PAST 4 candles\n",
            "46.25407166123778\n",
            "occured 307 times out of 20500\n",
            "PAST 3 candles\n",
            "50.55467511885895\n",
            "occured 631 times out of 20500\n",
            "PAST 2 candles\n",
            "51.24851367419738\n",
            "occured 841 times out of 20500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For tesla stock analysed based on its daily values. the daily strategy of buying right after the pattern down down up at any rsi value will guarentee you to make money\n",
        "#however these instances are very rare as they only occur 28 out of 300 days of trading. so snatch at the pattern when it appears.\n",
        "#this estimates to about 300 dollars a year, which is very minimal"
      ],
      "metadata": {
        "id": "KPxxk4igbfn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for NQ on a 5 min interval, it seems the best time to trade is when the rsi is between 35-45 or anything lower thsn that. The best interval to hold the stock is for 15 to 25 minutes\n",
        "#normally its best to hold the stock for only 15 min. it completely depends on circumstance. the overall percentage of the stock making money is 53-57 percent which is relatively low.\n",
        "#but if the right strategy is estabilshed and the trading is systematic the strategy will make money."
      ],
      "metadata": {
        "id": "kfb4LuG_KpKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TA-HKpRWSaVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}